{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ExplainableMachineLearningShap.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "nteract": {
      "version": "0.12.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5TeXp8UcMl6"
      },
      "source": [
        "Credit: This notebook is based on the contents of  https://github.com/TeamHG-Memex/eli5/blob/master/notebooks/TextExplainer.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1_Df4K6cMl7"
      },
      "source": [
        "# Debugging a black-box text classifier (LIME)\n",
        "\n",
        "Let’s look at the 20newsgroups dataset. This is a dataset that contains some discussions about news articles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZDvk6FBcMl-",
        "outputId": "92f9cad6-4831-4aea-8b5c-4a7d7b7befd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "categories = ['alt.atheism', \n",
        "              'soc.religion.christian', \n",
        "              'comp.graphics', \n",
        "              'sci.med']\n",
        "twenty_train = fetch_20newsgroups(subset='train', \n",
        "                                  categories=categories, \n",
        "                                  shuffle=True,\n",
        "                                  random_state=42, \n",
        "                                  remove=('headers', 'footers'))\n",
        "twenty_test = fetch_20newsgroups(subset='test', \n",
        "                                 categories=categories, \n",
        "                                 shuffle=True,\n",
        "                                 random_state=42, \n",
        "                                 remove=('headers', 'footers'))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading 20news dataset. This may take a few minutes.\n",
            "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eottpbHQcMl_",
        "outputId": "24888e3a-4aae-4cac-a7eb-30cba7939a4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "i = 125\n",
        "print(\"Class: {}\".format(twenty_train.target_names[twenty_train.target[i]]))\n",
        "print(\"-\"*20); print()\n",
        "sample = twenty_train.data[i]; print(sample)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class: alt.atheism\n",
            "--------------------\n",
            "\n",
            "In article <1993Apr3.153552.4334@mac.cc.macalstr.edu>, acooper@mac.cc.macalstr.edu writes:\n",
            "|> In article <1pint5$1l4@fido.asd.sgi.com>, livesey@solntze.wpd.sgi.com (Jon Livesey) writes\n",
            ">\n",
            "> Well, Germany was hardly the ONLY country to discriminate against the \n",
            "> Jews, although it has the worst reputation because it did the best job \n",
            "> of expressing a general European dislike of them.  This should not turn \n",
            "> into a debate on antisemitism, but you should also point out that Luther's\n",
            ">  antiSemitism was based on religious grounds, while Hitler's was on racial \n",
            "> grounds, and Wagnmer's on aesthetic grounds.  Just blanketing the whole \n",
            "> group is poor analysis, even if they all are bigots.\n",
            "\n",
            "I find these to be intriguing remarks.   Could you give us a bit\n",
            "more explanation here?   For example, which religion is anti-semitic,\n",
            "and which aesthetic?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihOcbNAIcMmB"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.spatial import distance\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.feature_selection import chi2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "inputHidden": false,
        "outputHidden": false,
        "id": "fzAo2AKHcMmD"
      },
      "source": [
        "As a black-box classifier we use a kernel svm with LSA features. This is clearly non-linear and hard to interpret. \n",
        "\n",
        "We will use `sklearn` pipelines. \n",
        "\n",
        "Often in ML tasks you need to perform sequence of different transformations (find set of features, generate new features, select only some good features) of raw dataset before applying final estimator.\n",
        "\n",
        "Pipeline gives you a single interface for all 3 steps of transformation and resulting estimator. It encapsulates transformers and predictors inside."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZSoT5EocMmD",
        "outputId": "8773011d-d8c3-4ae0-ca6f-24593f8a1d9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\n",
        "# LSA features\n",
        "vec = TfidfVectorizer(min_df=3, stop_words='english', ngram_range=(1, 2))\n",
        "svd = TruncatedSVD(n_components=100, n_iter=7, random_state=42)\n",
        "\n",
        "# SVM with rbf-kernel\n",
        "clf = SVC(C=150, gamma=2e-2, probability=True, kernel=\"rbf\")\n",
        "\n",
        "pipe = make_pipeline(vec, svd, clf)\n",
        "\n",
        "pipe.fit(twenty_train.data, twenty_train.target)\n",
        "pipe.score(twenty_test.data, twenty_test.target)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8901464713715047"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_GUr-UUcMmE"
      },
      "source": [
        "The dimension of the input documents is reduced to 100, and then a kernel SVM is used to classify the documents.\n",
        "\n",
        "This is what the pipeline returns for a document - it is pretty sure the first message in test data belongs to `sci.med`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "inputHidden": false,
        "outputHidden": false,
        "id": "mhmkX_jXcMmF",
        "outputId": "1d054eed-51f6-443b-8289-d2c7dd17715c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def print_prediction(doc):\n",
        "    y_pred = pipe.predict_proba([doc])[0]\n",
        "    for target, prob in zip(twenty_train.target_names, y_pred):\n",
        "        print(\"{:.3f} {}\".format(prob, target))    \n",
        "\n",
        "doc = twenty_test.data[0]\n",
        "print_prediction(doc)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.001 alt.atheism\n",
            "0.001 comp.graphics\n",
            "0.995 sci.med\n",
            "0.003 soc.religion.christian\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIJS5MUEcMmH"
      },
      "source": [
        "The algorithm **cannot provide a good explanation for a black-box classifier which works on character level or uses features that are not directly related to tokens**, depending on the interpretable representation choosen. \n",
        "\n",
        "But one can use `eli5.lime.TextExplainer` to debug the prediction - to check what was important in the document to make this decision.\n",
        "\n",
        "Create a `TextExplainer` instance, then pass the document to explain and a black-box classifier (a function which returns probabilities) to the TextExplainer.fit method, then check the explanation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "inputHidden": false,
        "outputHidden": false,
        "id": "9FKbOab4cMmH",
        "outputId": "088a45f0-6634-4256-b815-cc1be473db53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install eli5"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting eli5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/54/04cab6e1c0ae535bec93f795d8403fdf6caf66fa5a6512263202dbb14ea6/eli5-0.11.0-py2.py3-none-any.whl (106kB)\n",
            "\r\u001b[K     |███                             | 10kB 15.0MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 20kB 21.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 30kB 18.1MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 40kB 15.5MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 51kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 61kB 10.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 71kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 81kB 9.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 92kB 10.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 102kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 7.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.7/dist-packages (from eli5) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from eli5) (1.4.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from eli5) (0.8.9)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.7/dist-packages (from eli5) (21.2.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from eli5) (1.19.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from eli5) (2.11.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from eli5) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20->eli5) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->eli5) (2.0.1)\n",
            "Installing collected packages: eli5\n",
            "Successfully installed eli5-0.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "inputHidden": false,
        "outputHidden": false,
        "id": "REAynTpBcMmI",
        "outputId": "177e6f15-1c79-4985-9f62-a0b53988a446",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 753
        }
      },
      "source": [
        "import eli5\n",
        "from eli5.lime import TextExplainer\n",
        "\n",
        "te = TextExplainer(random_state=42)\n",
        "te.fit(doc, pipe.predict_proba)\n",
        "te.show_prediction(target_names=twenty_train.target_names)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=alt.atheism\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.000</b>, score <b>-8.365</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 97.57%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.414\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 80.73%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -7.951\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 94.98%); opacity: 0.81\" title=\"0.123\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.92%); opacity: 0.80\" title=\"0.035\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.68%); opacity: 0.82\" title=\"-0.212\">recall</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.07%); opacity: 0.81\" title=\"0.120\">from</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.58%); opacity: 0.82\" title=\"0.258\">my</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.81%); opacity: 0.81\" title=\"-0.095\">bout</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.08%); opacity: 0.81\" title=\"-0.120\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.56%); opacity: 0.86\" title=\"-0.731\">kidney</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.02%); opacity: 0.85\" title=\"-0.589\">stones</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 96.37%); opacity: 0.81\" title=\"0.078\">there</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.90%); opacity: 0.87\" title=\"0.895\">isn</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(120, 100.00%, 91.58%); opacity: 0.82\" title=\"0.258\">t</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.31%); opacity: 0.81\" title=\"-0.112\">any</span><span style=\"opacity: 0.80\">\n",
              "</span><span style=\"background-color: hsl(0, 100.00%, 86.57%); opacity: 0.84\" title=\"-0.503\">medication</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.23%); opacity: 0.82\" title=\"-0.274\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.58%); opacity: 0.81\" title=\"-0.103\">can</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.48%); opacity: 0.83\" title=\"0.308\">do</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.48%); opacity: 0.83\" title=\"0.308\">anything</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.10%); opacity: 0.82\" title=\"-0.236\">about</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.18%); opacity: 0.82\" title=\"-0.232\">them</span><span style=\"opacity: 0.80\"> except </span><span style=\"background-color: hsl(0, 100.00%, 94.21%); opacity: 0.81\" title=\"-0.151\">relieve</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.55%); opacity: 0.81\" title=\"-0.072\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 79.63%); opacity: 0.88\" title=\"-0.913\">pain</span><span style=\"opacity: 0.80\">.\n",
              "\n",
              "either </span><span style=\"background-color: hsl(0, 100.00%, 93.87%); opacity: 0.81\" title=\"-0.164\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.08%); opacity: 0.81\" title=\"-0.156\">pass</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 91.66%); opacity: 0.82\" title=\"0.255\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.12%); opacity: 0.81\" title=\"0.085\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.31%); opacity: 0.80\" title=\"-0.026\">have</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.23%); opacity: 0.83\" title=\"0.320\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.26%); opacity: 0.82\" title=\"0.188\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.60%); opacity: 0.82\" title=\"0.215\">broken</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.78%); opacity: 0.81\" title=\"-0.066\">up</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.13%); opacity: 0.80\" title=\"0.030\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.58%); opacity: 0.81\" title=\"-0.175\">sound</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 92.42%); opacity: 0.82\" title=\"0.222\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.12%); opacity: 0.81\" title=\"0.085\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.31%); opacity: 0.80\" title=\"-0.026\">have</span><span style=\"opacity: 0.80\">\n",
              "</span><span style=\"background-color: hsl(120, 100.00%, 90.23%); opacity: 0.83\" title=\"0.320\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.13%); opacity: 0.80\" title=\"0.010\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.68%); opacity: 0.81\" title=\"-0.068\">extracted</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.75%); opacity: 0.80\" title=\"0.039\">surgically</span><span style=\"opacity: 0.80\">.\n",
              "\n",
              "</span><span style=\"background-color: hsl(0, 100.00%, 93.68%); opacity: 0.81\" title=\"-0.171\">when</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.76%); opacity: 0.81\" title=\"-0.131\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.83%); opacity: 0.81\" title=\"-0.166\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.03%); opacity: 0.80\" title=\"0.032\">in</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 96.60%); opacity: 0.81\" title=\"-0.071\">the</span><span style=\"opacity: 0.80\"> x-</span><span style=\"background-color: hsl(0, 100.00%, 93.79%); opacity: 0.81\" title=\"-0.167\">ray</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.80%); opacity: 0.81\" title=\"-0.130\">tech</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.18%); opacity: 0.81\" title=\"-0.083\">happened</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.96%); opacity: 0.81\" title=\"-0.091\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.19%); opacity: 0.84\" title=\"0.419\">mention</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.56%); opacity: 0.81\" title=\"0.104\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.48%); opacity: 0.80\" title=\"-0.022\">she</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(0, 100.00%, 93.71%); opacity: 0.81\" title=\"-0.170\">d</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.15%); opacity: 0.81\" title=\"-0.153\">had</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.56%); opacity: 0.86\" title=\"-0.731\">kidney</span><span style=\"opacity: 0.80\">\n",
              "</span><span style=\"background-color: hsl(0, 100.00%, 85.02%); opacity: 0.85\" title=\"-0.589\">stones</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.51%); opacity: 0.81\" title=\"-0.178\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.59%); opacity: 0.82\" title=\"-0.258\">children</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 93.51%); opacity: 0.81\" title=\"-0.178\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.86%); opacity: 0.81\" title=\"-0.165\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.33%); opacity: 0.80\" title=\"-0.050\">childbirth</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.37%); opacity: 0.80\" title=\"-0.006\">hurt</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.65%); opacity: 0.81\" title=\"0.135\">less</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "    \n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=comp.graphics\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.000</b>, score <b>-8.683</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 98.08%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.296\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -8.388\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 99.25%); opacity: 0.80\" title=\"0.008\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.25%); opacity: 0.80\" title=\"0.008\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.50%); opacity: 0.84\" title=\"-0.454\">recall</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.64%); opacity: 0.81\" title=\"0.101\">from</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.98%); opacity: 0.81\" title=\"0.160\">my</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.28%); opacity: 0.82\" title=\"0.187\">bout</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.73%); opacity: 0.81\" title=\"-0.132\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 79.26%); opacity: 0.88\" title=\"-0.937\">kidney</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.84%); opacity: 0.87\" title=\"-0.836\">stones</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 98.48%); opacity: 0.80\" title=\"-0.022\">there</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.56%); opacity: 0.83\" title=\"-0.304\">isn</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(120, 100.00%, 96.20%); opacity: 0.81\" title=\"0.083\">t</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.36%); opacity: 0.80\" title=\"0.025\">any</span><span style=\"opacity: 0.80\">\n",
              "</span><span style=\"background-color: hsl(0, 100.00%, 82.50%); opacity: 0.86\" title=\"-0.735\">medication</span><span style=\"opacity: 0.80\"> that </span><span style=\"background-color: hsl(120, 100.00%, 98.75%); opacity: 0.80\" title=\"0.017\">can</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.48%); opacity: 0.80\" title=\"0.005\">do</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.04%); opacity: 0.80\" title=\"-0.032\">anything</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.78%); opacity: 0.81\" title=\"0.065\">about</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.78%); opacity: 0.81\" title=\"0.065\">them</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.71%); opacity: 0.80\" title=\"-0.018\">except</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.42%); opacity: 0.81\" title=\"-0.144\">relieve</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.38%); opacity: 0.83\" title=\"-0.312\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 63.49%); opacity: 0.98\" title=\"-2.101\">pain</span><span style=\"opacity: 0.80\">.\n",
              "\n",
              "</span><span style=\"background-color: hsl(0, 100.00%, 94.08%); opacity: 0.81\" title=\"-0.156\">either</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.14%); opacity: 0.81\" title=\"0.085\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.98%); opacity: 0.81\" title=\"0.123\">pass</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 97.12%); opacity: 0.80\" title=\"-0.056\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.80%); opacity: 0.81\" title=\"-0.130\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.14%); opacity: 0.80\" title=\"0.030\">have</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.92%); opacity: 0.81\" title=\"0.092\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.47%); opacity: 0.80\" title=\"-0.046\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.72%); opacity: 0.80\" title=\"0.002\">broken</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.41%); opacity: 0.81\" title=\"0.109\">up</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.79%); opacity: 0.81\" title=\"-0.167\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.27%); opacity: 0.81\" title=\"-0.081\">sound</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 97.12%); opacity: 0.80\" title=\"-0.056\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.80%); opacity: 0.81\" title=\"-0.130\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.14%); opacity: 0.80\" title=\"0.030\">have</span><span style=\"opacity: 0.80\">\n",
              "</span><span style=\"background-color: hsl(120, 100.00%, 95.92%); opacity: 0.81\" title=\"0.092\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.93%); opacity: 0.80\" title=\"-0.035\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.03%); opacity: 0.80\" title=\"0.012\">extracted</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.53%); opacity: 0.80\" title=\"0.021\">surgically</span><span style=\"opacity: 0.80\">.\n",
              "\n",
              "</span><span style=\"background-color: hsl(120, 100.00%, 94.78%); opacity: 0.81\" title=\"0.130\">when</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.07%); opacity: 0.80\" title=\"0.057\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.24%); opacity: 0.82\" title=\"-0.189\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.09%); opacity: 0.80\" title=\"0.057\">in</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 99.78%); opacity: 0.80\" title=\"0.001\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.12%); opacity: 0.81\" title=\"0.085\">x</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(120, 100.00%, 74.30%); opacity: 0.91\" title=\"1.272\">ray</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.31%); opacity: 0.80\" title=\"-0.007\">tech</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.72%); opacity: 0.83\" title=\"-0.344\">happened</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.94%); opacity: 0.81\" title=\"0.091\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.99%); opacity: 0.81\" title=\"0.089\">mention</span><span style=\"opacity: 0.80\"> that </span><span style=\"background-color: hsl(120, 100.00%, 98.49%); opacity: 0.80\" title=\"0.022\">she</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(120, 100.00%, 98.84%); opacity: 0.80\" title=\"0.015\">d</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.91%); opacity: 0.80\" title=\"-0.014\">had</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 79.26%); opacity: 0.88\" title=\"-0.937\">kidney</span><span style=\"opacity: 0.80\">\n",
              "</span><span style=\"background-color: hsl(0, 100.00%, 80.84%); opacity: 0.87\" title=\"-0.836\">stones</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.13%); opacity: 0.81\" title=\"-0.118\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.78%); opacity: 0.85\" title=\"-0.602\">children</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 99.93%); opacity: 0.80\" title=\"-0.000\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.49%); opacity: 0.82\" title=\"0.219\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.07%); opacity: 0.81\" title=\"0.157\">childbirth</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.12%); opacity: 0.83\" title=\"-0.373\">hurt</span><span style=\"opacity: 0.80\"> less.</span>\n",
              "    </p>\n",
              "\n",
              "    \n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=sci.med\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.996</b>, score <b>6.195</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(120, 100.00%, 83.72%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        +6.250\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 99.41%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.054\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(120, 100.00%, 97.99%); opacity: 0.80\" title=\"0.033\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.21%); opacity: 0.80\" title=\"-0.009\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.28%); opacity: 0.84\" title=\"0.466\">recall</span><span style=\"opacity: 0.80\"> from </span><span style=\"background-color: hsl(120, 100.00%, 98.60%); opacity: 0.80\" title=\"0.020\">my</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.62%); opacity: 0.81\" title=\"-0.136\">bout</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.95%); opacity: 0.81\" title=\"-0.061\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 77.65%); opacity: 0.89\" title=\"1.042\">kidney</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.27%); opacity: 0.87\" title=\"0.872\">stones</span><span style=\"opacity: 0.80\">, there </span><span style=\"background-color: hsl(0, 100.00%, 95.03%); opacity: 0.81\" title=\"-0.122\">isn</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(0, 100.00%, 98.59%); opacity: 0.80\" title=\"-0.020\">t</span><span style=\"opacity: 0.80\"> any\n",
              "</span><span style=\"background-color: hsl(120, 100.00%, 80.56%); opacity: 0.87\" title=\"0.854\">medication</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.04%); opacity: 0.80\" title=\"-0.058\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.74%); opacity: 0.81\" title=\"-0.169\">can</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.25%); opacity: 0.81\" title=\"-0.150\">do</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.36%); opacity: 0.81\" title=\"-0.110\">anything</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.72%); opacity: 0.80\" title=\"0.040\">about</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.50%); opacity: 0.81\" title=\"-0.106\">them</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.73%); opacity: 0.80\" title=\"0.002\">except</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.62%); opacity: 0.81\" title=\"0.174\">relieve</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.94%); opacity: 0.82\" title=\"0.243\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"2.394\">pain</span><span style=\"opacity: 0.80\">.\n",
              "\n",
              "</span><span style=\"background-color: hsl(120, 100.00%, 98.47%); opacity: 0.80\" title=\"0.023\">either</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.14%); opacity: 0.81\" title=\"-0.085\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.46%); opacity: 0.81\" title=\"-0.107\">pass</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 98.76%); opacity: 0.80\" title=\"0.017\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.05%); opacity: 0.80\" title=\"-0.032\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.53%); opacity: 0.80\" title=\"0.004\">have</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.62%); opacity: 0.80\" title=\"-0.042\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.36%); opacity: 0.80\" title=\"0.025\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.05%); opacity: 0.82\" title=\"-0.238\">broken</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.12%); opacity: 0.81\" title=\"-0.155\">up</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.44%); opacity: 0.81\" title=\"0.076\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.95%); opacity: 0.81\" title=\"0.061\">sound</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 98.76%); opacity: 0.80\" title=\"0.017\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.05%); opacity: 0.80\" title=\"-0.032\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.53%); opacity: 0.80\" title=\"0.004\">have</span><span style=\"opacity: 0.80\">\n",
              "</span><span style=\"background-color: hsl(0, 100.00%, 97.62%); opacity: 0.80\" title=\"-0.042\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.83%); opacity: 0.80\" title=\"-0.037\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.25%); opacity: 0.82\" title=\"-0.188\">extracted</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.91%); opacity: 0.81\" title=\"0.062\">surgically</span><span style=\"opacity: 0.80\">.\n",
              "\n",
              "when i </span><span style=\"background-color: hsl(120, 100.00%, 96.50%); opacity: 0.81\" title=\"0.074\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.94%); opacity: 0.80\" title=\"0.034\">in</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 97.32%); opacity: 0.80\" title=\"-0.050\">the</span><span style=\"opacity: 0.80\"> x-</span><span style=\"background-color: hsl(0, 100.00%, 84.30%); opacity: 0.85\" title=\"-0.629\">ray</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.81%); opacity: 0.82\" title=\"0.248\">tech</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.29%); opacity: 0.82\" title=\"-0.187\">happened</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.75%); opacity: 0.81\" title=\"-0.131\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.33%); opacity: 0.82\" title=\"-0.269\">mention</span><span style=\"opacity: 0.80\"> that she&#x27;d </span><span style=\"background-color: hsl(0, 100.00%, 97.63%); opacity: 0.80\" title=\"-0.042\">had</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.28%); opacity: 0.88\" title=\"1.000\">kidney</span><span style=\"opacity: 0.80\">\n",
              "</span><span style=\"background-color: hsl(120, 100.00%, 80.27%); opacity: 0.87\" title=\"0.872\">stones</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.70%); opacity: 0.81\" title=\"0.068\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.14%); opacity: 0.81\" title=\"-0.085\">children</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(0, 100.00%, 98.75%); opacity: 0.80\" title=\"-0.017\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.63%); opacity: 0.81\" title=\"-0.174\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.84%); opacity: 0.81\" title=\"-0.165\">childbirth</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.75%); opacity: 0.82\" title=\"0.251\">hurt</span><span style=\"opacity: 0.80\"> less.</span>\n",
              "    </p>\n",
              "\n",
              "    \n",
              "        \n",
              "    \n",
              "        \n",
              "        \n",
              "    \n",
              "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
              "            <b>\n",
              "    \n",
              "        y=soc.religion.christian\n",
              "    \n",
              "</b>\n",
              "\n",
              "    \n",
              "    (probability <b>0.004</b>, score <b>-5.497</b>)\n",
              "\n",
              "top features\n",
              "        </p>\n",
              "    \n",
              "    <table class=\"eli5-weights\"\n",
              "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
              "        <thead>\n",
              "        <tr style=\"border: none;\">\n",
              "            \n",
              "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
              "                    Contribution<sup>?</sup>\n",
              "                </th>\n",
              "            \n",
              "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "            \n",
              "        </tr>\n",
              "        </thead>\n",
              "        <tbody>\n",
              "        \n",
              "        \n",
              "\n",
              "        \n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 97.94%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -0.325\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        &lt;BIAS&gt;\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "            <tr style=\"background-color: hsl(0, 100.00%, 85.74%); border: none;\">\n",
              "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "        -5.172\n",
              "    </td>\n",
              "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "        Highlighted in text (sum)\n",
              "    </td>\n",
              "    \n",
              "</tr>\n",
              "        \n",
              "\n",
              "        </tbody>\n",
              "    </table>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n",
              "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
              "        <span style=\"background-color: hsl(0, 100.00%, 95.83%); opacity: 0.81\" title=\"-0.095\">as</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.22%); opacity: 0.80\" title=\"0.028\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.91%); opacity: 0.82\" title=\"-0.288\">recall</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.45%); opacity: 0.80\" title=\"0.023\">from</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.51%); opacity: 0.81\" title=\"-0.073\">my</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.06%); opacity: 0.82\" title=\"0.196\">bout</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.65%); opacity: 0.81\" title=\"0.173\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.09%); opacity: 0.87\" title=\"-0.884\">kidney</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.73%); opacity: 0.86\" title=\"-0.721\">stones</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 96.54%); opacity: 0.81\" title=\"0.073\">there</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.20%); opacity: 0.82\" title=\"0.232\">isn</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(0, 100.00%, 98.00%); opacity: 0.80\" title=\"-0.033\">t</span><span style=\"opacity: 0.80\"> any\n",
              "</span><span style=\"background-color: hsl(0, 100.00%, 85.01%); opacity: 0.85\" title=\"-0.589\">medication</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.38%); opacity: 0.80\" title=\"0.049\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.91%); opacity: 0.82\" title=\"0.288\">can</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.74%); opacity: 0.82\" title=\"0.296\">do</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.12%); opacity: 0.82\" title=\"0.194\">anything</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.63%); opacity: 0.80\" title=\"-0.042\">about</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.60%); opacity: 0.81\" title=\"0.174\">them</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.32%); opacity: 0.80\" title=\"0.026\">except</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.14%); opacity: 0.81\" title=\"-0.154\">relieve</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.60%); opacity: 0.82\" title=\"-0.258\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 66.37%); opacity: 0.96\" title=\"-1.868\">pain</span><span style=\"opacity: 0.80\">.\n",
              "\n",
              "</span><span style=\"background-color: hsl(0, 100.00%, 96.66%); opacity: 0.81\" title=\"-0.069\">either</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.33%); opacity: 0.81\" title=\"-0.111\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.34%); opacity: 0.82\" title=\"0.226\">pass</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 94.59%); opacity: 0.81\" title=\"0.137\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.88%); opacity: 0.81\" title=\"0.127\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.92%); opacity: 0.81\" title=\"0.062\">have</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.00%); opacity: 0.81\" title=\"0.123\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.87%); opacity: 0.80\" title=\"-0.036\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.00%); opacity: 0.83\" title=\"0.379\">broken</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.35%); opacity: 0.81\" title=\"0.146\">up</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.46%); opacity: 0.81\" title=\"-0.075\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.92%); opacity: 0.80\" title=\"-0.000\">sound</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 98.72%); opacity: 0.80\" title=\"0.018\">or</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.88%); opacity: 0.81\" title=\"0.127\">they</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.92%); opacity: 0.81\" title=\"0.062\">have</span><span style=\"opacity: 0.80\">\n",
              "</span><span style=\"background-color: hsl(120, 100.00%, 95.00%); opacity: 0.81\" title=\"0.123\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.05%); opacity: 0.81\" title=\"0.157\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.25%); opacity: 0.83\" title=\"0.319\">extracted</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.99%); opacity: 0.81\" title=\"-0.090\">surgically</span><span style=\"opacity: 0.80\">.\n",
              "\n",
              "</span><span style=\"background-color: hsl(0, 100.00%, 94.83%); opacity: 0.81\" title=\"-0.129\">when</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.79%); opacity: 0.80\" title=\"-0.038\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.13%); opacity: 0.80\" title=\"0.030\">was</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.99%); opacity: 0.81\" title=\"-0.090\">in</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 96.59%); opacity: 0.81\" title=\"0.071\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.54%); opacity: 0.81\" title=\"0.177\">x</span><span style=\"opacity: 0.80\">-</span><span style=\"background-color: hsl(120, 100.00%, 95.16%); opacity: 0.81\" title=\"0.117\">ray</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.02%); opacity: 0.82\" title=\"-0.197\">tech</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.32%); opacity: 0.83\" title=\"0.412\">happened</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.47%); opacity: 0.82\" title=\"0.180\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.15%); opacity: 0.83\" title=\"0.371\">mention</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.17%); opacity: 0.82\" title=\"0.192\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.18%); opacity: 0.80\" title=\"0.054\">she</span><span style=\"opacity: 0.80\">&#x27;</span><span style=\"background-color: hsl(120, 100.00%, 98.29%); opacity: 0.80\" title=\"0.026\">d</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.78%); opacity: 0.80\" title=\"0.038\">had</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.09%); opacity: 0.87\" title=\"-0.884\">kidney</span><span style=\"opacity: 0.80\">\n",
              "</span><span style=\"background-color: hsl(0, 100.00%, 82.73%); opacity: 0.86\" title=\"-0.721\">stones</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.70%); opacity: 0.81\" title=\"-0.068\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.37%); opacity: 0.84\" title=\"0.461\">children</span><span style=\"opacity: 0.80\">, </span><span style=\"background-color: hsl(120, 100.00%, 98.59%); opacity: 0.80\" title=\"0.020\">and</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.77%); opacity: 0.81\" title=\"0.097\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.05%); opacity: 0.81\" title=\"0.088\">childbirth</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.51%); opacity: 0.81\" title=\"-0.074\">hurt</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.97%); opacity: 0.81\" title=\"-0.090\">less</span><span style=\"opacity: 0.80\">.</span>\n",
              "    </p>\n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmr6mBSTcMmJ"
      },
      "source": [
        "Explanation makes sense - we expect reasonable classifier to take highlighted words in account. But how can we be sure this is how the pipeline works, not just a nice-looking lie? A simple sanity check is to remove or change the highlighted words, to confirm that they change the outcome:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "inputHidden": false,
        "outputHidden": false,
        "id": "rQPizl4rcMmK",
        "outputId": "2e6033db-a22e-432c-edbc-0c07645503e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import re\n",
        "doc2 = re.sub(r'(recall|kidney|stones|medication|pain|tech)', \n",
        "              '', \n",
        "              doc, \n",
        "              flags=re.I)\n",
        "print_prediction(doc2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.066 alt.atheism\n",
            "0.154 comp.graphics\n",
            "0.351 sci.med\n",
            "0.429 soc.religion.christian\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "inputHidden": false,
        "outputHidden": false,
        "id": "gFhwjlD-cMmL"
      },
      "source": [
        "Predicted probabilities changed a lot indeed.\n",
        "\n",
        "And in fact, `TextExplainer` did something similar to get the explanation. `TextExplainer` generated a lot of texts similar to the document (by removing some of the words), and then trained a white-box classifier which predicts the output of the black-box classifier (not the true labels!). The explanation we saw is for this white-box classifier.\n",
        "\n",
        "This approach follows the LIME algorithm; for text data the algorithm is actually pretty straightforward:\n",
        "\n",
        "1. generate distorted versions of the text;\n",
        "2. predict probabilities for these distorted texts using the black-box classifier;\n",
        "3. train another classifier (one of those eli5 supports) which tries to predict output of a black-box classifier on these texts.\n",
        "\n",
        "The algorithm works because even though it could be hard or impossible to approximate a black-box classifier globally (for every possible text), approximating it in a small neighbourhood near a given text often works well, even with simple white-box classifiers.\n",
        "\n"
      ]
    }
  ]
}